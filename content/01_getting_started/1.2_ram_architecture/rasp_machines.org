#+title: RASP Machines
#+subtitle: Computation Model to Better Compare Algorithms
#+author: Franck Chauvel
#+date: May 22, 2021
#+language: en


#+SETUPFILE: ../templates/style.org


* Measuring /Complexity/?

  So we are to compare programs, but what are we after? There are many
  properties that one can be interested in, such as length (in line of
  code), readability, performance, or memory to name only a few.

  Here we are interested in *algorithmic complexity*, which stands for
  both the time and memory required to obtain a result. Algorithmic
  complexity is not the same concept with /cyclomatic complexity/,
  which is a metric that reflects code readability.

  Yet the first challenge is to see the algorithm behind our program!  In
  practice, we do not write algorithms, but *programs*, which are
  written is a given programming language, say, Java, C, Python for
  example. These programs execute on various type of hardware ranging
  from tiny embedded micro controller to large virtual machine running
  in the cloud. To dig out the algorithms, we must get rid of all the
  technicalities and keep only the gist.

* Comparing Programs

  Let's start with an example, two programs that both compute the sum
  of even integer until 100. The first program I wrote in C and the
  second in Python.

  #+caption: C program to compute the sum of even integers (until 100), using a loop.
  #+name: with_a_loop 
  #+begin_src C -n :results output :cache yes :exports both :tangle experiments/sum.c
    #include <stdio.h>

    #define LIMIT 100

    int main(int argvc, char** argv) {
      int sum = 0; 
      for (int any_integer=0; any_integer <= LIMIT ; any_integer++) {
        if (any_integer % 2 == 0) {
          sum += any_integer;
        }
      }
      printf("Total: %d\n", sum);
    }
   #+end_src

   #+RESULTS[f7cc5876da7d322b0375a75c6dc9681f44515658]: with_a_loop
   : Total: 2550

   I chose to write the second program in Python. This one does not
   use a loop but a formula to compute the sum of even integer, namely
   $\sum_{i=1}^{n} i = \frac{n\cdot(n+1)}{2}$.

   #+name: with_a_formula
   #+caption: A alternative Python program to compute the sum of even integers until 100
   #+begin_src python :python python3 :results output :exports both :cache yes :tangle experiments/sum.py
     LIMIT = 100

     half = LIMIT / 2
     total = half * (half + 1)
     print(f"Total: {total}")
   #+end_src

   #+RESULTS[58ae01dfd2d65c91ce40f7f2c98b37e6e947f530]: with_a_formula
   : Total: 2550.0

   #+begin_note
   Where does this formula come from? Well, let's work out the
   math. If we take the sum $s$ of even integers, we get $s = 2 + 4 +
   6 + \ldots + n$ where n is the our limit (i.e., 100).  By
   definition we can factor out 2, because each integer is even, and
   so we get $s = 2 \cdot (1 + 2 + 3 + \ldots + n/2)$. We can further
   simplify the second term because there is a formula $\sum_{i=1}^{n}
   i = \frac{n\cdot(n+1)}{2}$. So we get $s = 2 \times
   \sum_{i=1}^{n/2} i$
   #+end_note
   
   
** Measuring Execution Time

   So which one is best? Difficult to say from the outset. The first
   program includes a loop, but it runs in C, which compiles to native
   code. Let see what we get if we where to measure.

   #+begin_warning
   Note that measuring the time a program takes to run (or the memory
   it consume) is known as /performance testing/, and is a complex
   task. What we do below is naive and none would proceed this way.
   #+end_warning
   
   #+caption: Timing our C-program
   #+name: timing_c_program
   #+begin_src shell :results output :cache yes :exports both :dir ./experiments :prologue exec 2>&1
     gcc sum.c
     time ./a.out
   #+end_src

   #+RESULTS[f2778347ff383df2dbae9aef3409d1ecdd69c174]: timing_c_program
   : Total: 2550
   : ./a.out  0.00s user 0.00s system 2% cpu 0.189 total

   On my laptop that about 195 ms to run as show the output above.

   Let's move on to our second program written in Python. Here we can
   measure the time it takes in a similar way.

   #+name: timing_python
   #+caption: Timing our Python program
   #+begin_src shell :results output :cache yes :exports both :dir ./experiments :prologue exec 2>&1
     time python3 sum.py
   #+end_src

   #+results: timing_python
   : Total: 2550.0
   : python3 sum.py  0.02s user 0.01s system 93% cpu 0.022 total

   This one takes about 23 ms to run. It seems this one is definitely
   faster.

   But could it be that the first program is faster, simply because it
   is compiled to machine code whereas the second one is interpreted?
   To make a fair comparison, we must abstract away the underlying
   compiler (or interpreter) and hardware. To do this, we will use /an
   abstract machine/, the RAM.  
  
* Abstract Random Access Machine

  How does it works? A RASP machine is a minimal model of computation,
  but one that resemble a real computer.

  [[https://en.wikipedia.org/wiki/Random-access_machine][Random access machines (RAM)]] is a family of abstract machine that we
  will use to get rid of the difference between our programs. Unlike
  other abstract machines such as the Turing machines, RAM machine
  resemble an actual computer and are thus easier to manipulate---I
  think, at least. There are at least two main alternative RAM
  architectures: RAM and RASP. In the original RAM [[cite:cook1973]], the
  program and the data are in two separate memory (i.e., this is a
  example of Harvard architecture). In RASP machines, the data and the
  program are placed in the same memory, as in a Von Neumann
  architectures.

  A RASP machine is a minimal computer with a CPU, a memory, and an
  input-output device.

  - The /CPU/ includes two registers, an accumulator ~ACC~ and a
    instruction pointer ~IP~. Each can only an arbitrary large signed
    integer value, but no floating point number.
  - The /RAM memory/ has an infinite number cells, each containing a
    single signed integer value. Each cell addressable by its index,
    which is also an integer value.
  - The I/O device let the user and the RAM machine exchange integer
    values.
    

  The initial definition of RASP machine [[cite:cook1973]] defines six
  instructions listed in the following table, together with their
  impact on both the CPU registers and the memory. Each instruction
  has a single operand, which is an integer value.

  #+caption: Instructions of the RASP machine
  #+name: table:rasp-instructions
  | Op. Code | Memonic         | Description                               | Semantic               |
  |----------+-----------------+-------------------------------------------+------------------------|
  |        6 | READ <address>  | Read a the  from the inputs device        | memory[address] := I/O |
  |          |                 |                                           | IP := IP + 2           |
  |----------+-----------------+-------------------------------------------+------------------------|
  |        7 | PRINT <address> | Print the value contained in the          | I/O := memory[address] |
  |          |                 | memory at the given address onto          | IP := IP +2            |
  |          |                 | the I/O device.                           |                        |
  |----------+-----------------+-------------------------------------------+------------------------|
  |        4 | STORE <address> | Store the value =ACC= into the            | memory[address] := ACC |
  |          |                 | memory at the given <address>             | IP := IP +2            |
  |----------+-----------------+-------------------------------------------+------------------------|
  |        1 | LOAD <value>    | Set the =ACC= register to the             | ACC := value           |
  |          |                 | given value                               | IP := IP + 2           |
  |----------+-----------------+-------------------------------------------+------------------------|
  |        2 | ADD <value>     | Add the given value to the =ACC=          | ACC := ACC + value     |
  |          |                 | register                                  | IP := IP +2            |
  |----------+-----------------+-------------------------------------------+------------------------|
  |        3 | SUB <value>     | Subtract the given value from the         | ACC := ACC - value     |
  |          |                 | ACC = register                            | IP := IP - 2           |
  |----------+-----------------+-------------------------------------------+------------------------|
  |        5 | JUMP <address>  | Set the =IP= register the givenf address, | if ACC >= 0:           |
  |          |                 | only if =ACC= is greater than or equal to | IP := address          |
  |          |                 | zero.                                     | else                   |
  |          |                 |                                           | IP := IP + 2           |
  |----------+-----------------+-------------------------------------------+------------------------|
  |        * | HALT <value>    | Stop the machine, regardless of th        |                        |
  |          |                 | given value                               |                        |

** Programs for RAM machines

   So to execute a program on a RAM machine, we need to load in memory
   a sequence of integers corresponding to our instructions. To run
   our [[lst:ram-echo][Echo program]] (below) we must first load in memory the values =6
   50 7 50=. These are the four memory cells needed to represent the
   two instructions of our program. The first =6= is the opcode of the
   =READ= instruction, followed by =50=, the address where the value
   should be stored. The following =7= is the opcode of the =PRINT=
   instruction, followed by the address where the value should be
   read, that is =50=.

   We implicitly separated the memory into two segments: one for the
   code and one for the data. The code segment starts at address 0,
   whereas the data segment starts at address 50.

   #+caption: A simple "echo program" for the RAM machine
   #+label: lst:ram-echo
   #+begin_src asm -n
   READ 50
   PRINT 50
   #+end_src

   Writing such sequence of integers quickly becomes annoying and we
   can come up with a fake assembly language, which allows us to
   define variable and avoid direct manipulation of addresses.

   #+caption: A RAM assembly program that adds two integers read from the I/O
   #+label: lst:asm-add-two-numbers
   #+begin_src asm -n
     segment: data
        value  1  0          ; value := 0

     segment: code
        read value           ; value := user-input
        load 0               ; ACC := 0
        add value            ; ACC := ACC + value
        read value           ; value := user-input
        add value            ; ACC := ACC + value
        store value          ; value := ACC
        print value          ; 
        halt
   #+end_src

   The syntax explicitly defines a code and a data segment. The
   assembler decides where these segments will be placed in memory,
   and hence it substitutes the right addresses for each symbol, be it
   a label or a variable (e.g., =value=).

** Efficiency of RAM Programs

   As a machine, the RAM machine is useless, but as an abstraction it
   enables a non-ambiguous definition of efficiency, both for time and
   space. The two key points of the RAM model are:

   1. Each arithmetic instruction takes one CPU-cycle.
   2. Each memory access takes /one CPU cycle/.
      
*** Time-complexity

    Again /time-complexity/ is the time a program takes to run. On our
    RAM machine, this boils down to counting CPU cycles, that is the
    number of instruction that are executed.

    Here we see the limitations of the RAM model. A real computer
    architecture as a limited register size, say 32-bit. This means
    that each register contains 16 binary digit, so the maximum number
    that can be represented is $2^{16}$, that is $65~536$. To manipulate
    larger numbers, a machine needs multiple CPU cycles.

    As a first example, let us consider our [[lst:asm-add-two-numbers][program that adds two
    integers]]. Here the program runs from start to finish without
    interruption, so it takes exactly eight cycles to complete, one
    cycle per instructions.

    Let us now consider [[lst:asm-add-n-integers]["add n integers" program]], which involves a
    loop. Here the program first prompts the user for the number of
    integers she wants to add and then, reads and adds these n numbers.

    #+caption: Complexity of a simple program adding 10 integers provided by the user.
    #+label: lst:asm-add-n-integers
    #+begin_src asm -n
      segment: data                ;
        value   1     0            ; var value := 0
        counter 1     0            ; var counter := 0
        limit   1    10            ; var limit := 10

      segment: code                ;
         loop:  load    0          ;
                add     counter    ;
                subtract limit     ;
                jump     done      ; while counter < limit
                load     0         ;      
                add      value     ;   ACC := value
                read     value     ;   value := user-input()
                add      value     ;
                store    value     ;   ACC := ACC + value
                load     1         ;
                add      counter   ;
                store    counter   ;   counter := counter + 1
                load     0         ;
                jump     loop      ; end-loop
        done:   print    value      
                halt           
    #+end_src

    /How many cycles does this program take to complete?/ As the limit
    is set to 10, the loop will be executed 10 times, but the
    condition (from the =loop= label to the =jump done=) will be
    executed an extra time, when the loop invariant does not hold
    anymore. In total, the 4 instructions of the condition are
    executed 11 times, 10 instructions of the loop body are executed
    10 times, and the 2 final instructions (from =print value=) are
    executed once. The gives us $4\times 11 + 10 \times 10 + 2 \times
    1$, which is $146$.

*** Space Complexity

    The space complexity of a program reflect the memory required to
    run it, that is simply the number of memory cells used.
    
    Let's continue with our [[lst:asm-add-n-integers][program that adds n integers]] as an
    example. This program does not allocate memory dynamically, so we
    can simply count the memory cells reserved by the program. The
    data segment declares three variables, namely =value=, =counter=,
    and =limit=, all of which take a single memory cells. So that is 3
    memory cells. The code segment contains 16 instructions, and each
    requires two memory cells, for a total of $16 \times 2 = 32$. In
    total this programs requires $3 + 32 = 35$ cells.

    The custom is however to not account for the space consumed by
    the code segment, so the space-complexity of this programs is
    only 3, the memory taken by the data segment.

*** TODO Cost models?
    
* Comparing Program, Again
   
** Converting our C-program

   Now that we know how to measure both the time- and space-complexity
   of RAM programs we can compare our [[with_a_loop][C program]] with our [[with_a_formula][Python
   program.]]

   The first hurdle is that our [[with_a_loop][C program]] contains an modulo
   operation, an arithmetic operation that the RAM machine does not
   support (as shown in [[table:rasp-instructions][the table of instructions]]). To circumvent
   this, we will simply assume a new operation, =MOD <value>=, which
   puts in the =ACC= register the remainder of the division of the
   =ACC= register by the given value. As for other arithmetic
   operation, we assume this =MOD= instruction takes exactly one CPU
   cycle to execute.

   We can now translate our C code into RAM assembly as shown below.

   #+caption: Our C-program, rewritten for the RASP machine
   #+name: asm-with-loop
   #+begin_src asm -n
     segment: data
        limit          1    100
        sum            1    0
        any_integer    1    0
        divisor        1    2
        shift          1    1

     segment: code
        loop:   load 0              ; 01
                add  any_integer    ; 02
                subtract limit      ; 03
                jump done           ; 04 while any_integer < limit
                load 0              ; 05
                add any_integer     ; 06
                mod divisor         ; 07
                subtract shift      ; 08
                jump skip           ; 09  if any_integer % 2, goto skip
                load 0              ; 10       
                add sum             ; 11
                add any_integer     ; 12 
                store sum           ; 13    sum := sum + any_integer
        skip:   load 1              ; 14  
                add any_integer     ; 15
                store any_integer   ; 16  any_integer := any_integer + 1
                load 0              ; 17
                jump loop           ; 18  goto loop
        done:   print sum           ; 19
                halt                ; 20
   #+end_src

   
*** Time-complexity

    So how long will our C-program takes when running on the RASP
    machine. Let's look at each part separately. Here are the parts:
    
    1. /the loop test/. This corresponds to the four first assembly
       instructions. As for the previous example, these instructions
       will 101 times, that is until the condition breaks. That is 404
       cycles.

    2. /the inner conditional/ (i.e., ~if (any_integer % 2 == 0)~),
       which corresponds to the 5 lines until the ~jump skip~
       instructions. These will be executed for every integer lesser
       than 100, that is 500 cycles.

    3. /the conditional body/, where we increment the sum once we
       found an even integer. These are lines 10 -- 13, which are run
       only for every even integer, that is 50 times. That is another
       200 cycles.

    4. /the loop increment/, where we increment the
       ~any_integer~Â value and jump back to the beginning of the
       loop. These are lines 14 -- 18, which runs for every
       integers. That is another 500 cycles.

    5. Finally the program print the result and stops, that's another
       two instructions that runs only once.

   The grand total is thus 1 606 cycles (i.e., $404 + 500 + 200 +
   500 + 2$).

*** Space-complexity

    Let's turn now to the space-complexity, that is the number of
    memory cells used by programs.

    Looking at the data segment, we see that our program declares 5
    variables of size 1. That is a space-complexity of 5.

   
** Converting our Python Program

   We can now turn to our [[with_a_formula][Python program]], but we face a missing
   instruction as well. Our code include a multiplication and a
   division, which the RASP machine does not support. As for the
   modulo operation in our [[with_a_loop][C program]], we will assume two new instructions:

   1. a =MUL <value>= instructions, which multiplies the content of
      the ACC register with the given value and places the result back
      in the ACC register. As other instructions, its take 1 CPU cycle
      to complete.

   2. a =DIV <value>= instruction, which divides the content of the
      =ACC= register by the given value and place the result back in
      the =ACC= register. This also takes a single CPU cycle to
      complete.

   With these two new instructions, we can now convert our [[with_a_formula][Python
   program]] to the [[code.asm-with-formula][following assembly program]].

   #+caption: Our [[with_a_formula][Python program]] rewritten for the RASP machine
   #+name: code.asm-with-formula
   #+begin_src asm -n
     segment: data
        limit 1    100
        half  1    0
        divisor 1   2
        increment 1   1
        result    1   0
        
     segment: code
        load 0
        add  limit
        div  divisor
        store half
        add  increment
        mul  half 
        store result
        print result
   #+end_src

*** Time-complexity

    This program is much simpler than the previous, because it does
    not have a loop. Its time-complexity is simply its number of
    instructions, that is 8.

    
*** Space-complexity

    The space-complexity of this program is the number of memory cells
    required by the data segment, that is, 5.

** So, Who is Best?

   From the data we have gathered, it is clear that our [[with_a_formula][Python
   solution]] (the one that uses a formula), is the fastest.

   #+caption: Comparison of the time- and space-complexity of both the C and Python programs
   #+name: table:comparison
   | Solution       | Time (cycles) | Space (cells) |
   |----------------+---------------+---------------|
   | [[with_a_loop][C program]]      | 1606          | 5             |
   | [[with_a_formula][Python program]] | 8             | 5             |

   As shown in [[table:comparison][the table above]], as for time-complexity, our solution
   with a loop takes more 1 000 cycles (or instructions) whereas our
   solution with a formula takes only 8 cycles. Looking now at
   space-complexity, both solution are equivalent and use 5 memory
   cells.

    
* Summary

  We have already covered quite some ground in this lecture, trying
  /comparing the efficiency of programs/. We look at summing up the
  first 100 even integers, and we wrote two programs, one in C, with a
  loop, and the other in Python with a formula.

  1. When we measure execution time, we saw that these two solutions
     are comparable, but this is like comparing apples with oranges,
     because these two programs are written in different programming
     languages, and could run on different hardware.

  2. To mitigate that, we introduced random access machine. This is a
     minimal abstract machine that resembles an actual computer. We
     saw how to measure time- and space-complexity on this abstract
     machine:

     1. /time-complexity/ is the number of CPU cycles needed to get to
        the results

     2. /space-complexity/ is the number of memory cells (program aside) needed
        to get the results

  3. Returning to our two programs our solution, with a loop requires
     more 1 500 CPU cycles, whereas out formula-based solution takes
     only 8!

  This is only the beginning of the journey. There are many ways to
  convert a high-level language like C or Python to machine
  instructions---the very job of a compiler. This is something we also
  want to get rid of, in order to properly compare algorithms, and not
  mere programs. Besides, so far we have only worked with programs
  that do not accept input parameters. We will see in the next lecture
  how to describe programs whose time- and space- complexity varies
  depending on their arguments. Think of summing the 100 first even
  integer, where the limit is not hard-coded, but rather given by the
  user. Besides,


bibliographystyle:plain
bibliography:~/notes/references.bib

