\documentclass{aldast}

\usepackage{verbatimbox}
\usepackage[mode=buildnew]{standalone}


\title{Algorithm Correctness}
\author{F. Chauvel}
\documentType{Lecture Notes}
\documentNumber{1.3}


\begin{document}

\maketitle

\begin{abstract}
  We look at methods to check that an algorithm actually solves the
  problem that it is meant to solve, and solve it completely. That is,
  we try to find bugs. We contrast two techniques, namely testing and
  mathematical proofs. Checking correctness helps understand
  algorithms.
\end{abstract}

\section*{Introduction}

% We solve problems by implementing algorithms using programs that
% runs on machines.
An algorithm is the sequence of steps one must follow to solve a
computational problem. To automate that, we encode our algorithms into
\emph{programs} that machines can execute, mechanically. We saw for
example how random access machines can load and execute programs as
sequences of 8 basic instructions.

% The star alignement
For this to work in real-life, everything must be right: Our algorithm
must solve our problem, the program must accurately \emph{implement}
our algorithm, and the machine must not fail in middle of the
execution. That is a lot that must be correct at the same time.

% Why does it matters, because algorithm are embedded into larger
% system, and their failure may take down the whole system.
\emph{Correctness} is more important than ever. Health, energy, banks,
transportation \ldots everything rely on software. Algorithms are
embedded everywhere into these much larger infrastructure where the
smallest bug is always expensive and
sometimes---unfortunately---deadly. For example, on June 4, 1996, the
European space launch vehicle Ariane 5 exploded after 40 s. of flight
because of a software error. 500 millions USD gone up in
smoke~\cite{nuseibeh1997}. Why do software fail? This is a difficult
question that goes way beyond the scope of this course. Building a
system is difficult and encompasses people, resources, project
management, software, hardware\sidenote{Check out
  \href{https://spectrum.ieee.org/lessons-from-a-decade-of-it-failures}{``Lessons
    learned from a decade of IT failures''}.}.

In this lecture, we focus on algorithms and we assume that both the
machine and the translation into an executable programs work just
fine. What remains is \emph{functional correctness}: Ensuring that the
algorithm adheres to its specification. We will look at two
techniques, namely \emph{testing} and \emph{formal verification}, as
means to establish this functional correctness, and, in turn, to
deepen our understanding of algorithms.

\section{Functional Correctness}

We saw that an algorithm solves a computational problem. This problem
is often described by a mathematical function that tells us the which
output to expect given a valid input. This function forms \emph{the
  specifications} of our what our algorithm should do. This is the
\emph{requirements}. To be \emph{totally correct}, an algorithm must
do two things:

\marginnote{%
 \begin{algorithm}[H]
    $x \gets 0$\;
    \While{$x < 100$}{
      $x \gets 1$\;
    }
  \end{algorithm}
  \captionof{figure}{An algorithm that never terminates.}
  \label{fig:infinite-loop}
}
\begin{itemize}
\item It must \emph{terminate} at some point. In other words, the RAM
  must reach an \texttt{HALT} instruction and stops. If it does not
  always terminate, the algorithm is, at best, partially
  correct. Figure~\ref{fig:infinite-loop} gives an example of
  algorithm that never terminate.
\item When it terminates, it must produce a correct output for all
  possible valid inputs. A correct output satisfies the constraints
  set by the problem. An algorithm is thus \emph{incorrect} if one can
  found at least one set of inputs for which the algorithm output is
  wrong.
\end{itemize}

\begin{takeaway}
  Provided with valid inputs, an algorithm ...
  \begin{itemize}
  \item is \emph{partially correct} when it \emph{never} terminates
    with an incorrect result, but may not terminate.
  \item is \emph{totally correct} when it \emph{always} terminates with a correct result.
  \end{itemize}
\end{takeaway}

Figures~\ref{fig:problem} and \ref{fig:algorithm} gives an example of
the challenge we face: How can we be sure that an algorithm
\emph{correctly} solve a problem? Figure~\ref{fig:problem} shows the
problem, which is to multiple to numbers $x$ and
$y$. Figure~\ref{fig:algorithm} shows a possible algorithm (in
pseudocode) which repeatedly adds $x$, $y$ times.

\begin{figure}[htbp]
\centering
\begin{minipage}{.475\textwidth}
  \begin{align*}
    product: \mathbb{N} \times \mathbb{N} & \to \mathbb{N} \\
    product \, (x, y) & =  x \times y
  \end{align*}
  \captionof{figure}{A problem: Multiplying two integers}
  \label{fig:problem}
\end{minipage}%
\hfill
\begin{minipage}{.475\textwidth}
  \begin{center}
  \begin{algorithm}[H]
    \KwIn{$(x,\,y) \in \mathbb{N}^2$}
    \KwOut{$product = x * y$}
    $product \gets 0$\;
    $counter \gets 0$\;
    \While{$counter < y$}{
      $product \gets product + x$\;
      $counter \gets counter + 1$\;
    }
  \end{algorithm}
\end{center}
  \captionof{figure}{A possible algorithm to compute the product}
  \label{fig:algorithm}
\end{minipage}
\end{figure}

% Pre and post condition

\begin{takeaway}
  A \emph{pre-condition} is what we assume to hold \emph{before} we execute instructions
  A \emph{post-condition} is what we assume to hold \emph{after} we executed instructions
\end{takeaway}

% Two approaches? Proving and testing


\section{Formal Proofs}

Can we prove \emph{functional correctness}? Establishing rigorously
that our algorithm delivers on its promises would give us a strong
sense of confidence. Let us how to proceed.

\subsection{Deduction System for Algorithm}

A formal proof~\cite{harrison2008}\sidenote{We have been writing
  proofs since centuries, but the notion of formal proof has only been
  formalized in 20th century.} is not a natural language argument. It
is a calculation that follows precise rules. It relies on a formal
notation so that that proofs can be checked mechanically---by a so-called
\emph{proof assistant}.

We have all been through proofs in
school. Figure~\ref{fig:formal-proof} shows an example taken from
Calculus, which establishes that $(x+1)^2 = x^2 + 2x + 1$.

\begin{figure}[htbp]
  \begin{minipage}[]{0.95\textwidth}
    \begin{align*}
      f(x) &= (x+1)^2 \\
           &= (x+1) \cdot (x+1) \tag{definition of square} \\
           &= [x\cdot(x+1)] + [1\cdot(x+1)] \tag{distributivity of $\times$ over $+$} \\
           &= [x\cdot(x+1)] + (x+1) \tag{neutral element of $\times$} \\
           &= [(x \cdot x)+ (x \cdot 1)] + (x+1) \tag{distributivity of $\times$ over $+$} \\
           &= [(x \cdot x)+ x] + (x+1) \tag{neutral element of $\times$} \\
           &= [(x^2)+ x] + (x+1) \tag{definition of square} \\
           &= x^2+ x + x + 1 \tag{associativity of $+$} \\
           &= x^2+ 2x + 1 \tag{factorization} \\
    \end{align*}
  \end{minipage}
  \caption{A formal proof that $(x+1)^2 = x^2 + 2x +1$. On the right,
    we see the inference rule used to derive each statement from the
    previous one.}
  \label{fig:formal-proof}
\end{figure}

Figure~\ref{fig:formal-proof} illustrates the key components of a
formal proof. A proof is a sequence of statements, each derived by an
agreed-upon \emph{inference rule}. The first statement, called the
\emph{premises}, captures what we assume to be true. The last
statement, called the \emph{conclusion}, captures a new fact we
logically derive from the premises.

The same applies directly to algorithms and data structures. The
statement we make describe the state of the machine. We will use the
semantic defined for RAM instructions as rules to explain why the
state of the machine changes over
time. Figure~\ref{fig:deduction-system} portrays this parallel between
reasoning about program correctness and reasoning about numbers.

\begin{figure}[htbp]
  \begin{center}
    \includestandalone[width=.8\textwidth]{images/proof-idea.tikz}
  \end{center}
  \caption{The \emph{deduction system} to reason about program correctness}
  \label{fig:deduction-system}
\end{figure}

\begin{takeaway}
  The \emph{syntax} and the \emph{semantic} of the language (i.e., the computation
  model) are the basis of the \emph{deduction system} we use to reason
  about the correctness of algorithm.
\end{takeaway}

\subsection{Assignments}
\label{sec:assignment}

Let us go step by step. What would it mean to prove the correctness of
a single assignment? Consider the following for example.

\begin{equation}
  counter \gets counter + 1
\end{equation}

Intuitively, if this is correct, we expect that the value $v$ of
our $counter$ variable \emph{after} the assignment be
equal to the value of that same variable \emph{before} it
(denoted by $v'$) plus one. What we want to prove is thus
$v = v' + 1$.

We know from the RAM computation model, that this translates into the
following three instructions, where \texttt{counter} denotes the
memory address where $v$ is stored.

\begin{minted}{asm}
  LOAD  1
  ADD   counter
  STORE counter
\end{minted}

But for the machine to execute these three instructions, the machine
should be correctly setup. We need the following assumptions:
\begin{itemize}
\item Our three instructions are loaded into memory, in
  contiguous cells, say from address $k$ to $k+5$. Remember each
  instruction occupies two memory cells, one for the operation code
  and one for the argument.
\item The machine is ready to execute the first instruction, that is
  $\mathit{IP} = k$.
\item The memory contains the value $v'$ at address \texttt{counter},
  but this address cannot be in the interval $[k, k+5]$.
\end{itemize}

Figure~\ref{fig:assignment} details how the machine state changes as
it progresses through our three instructions. The first instruction
resets the $\mathit{ACC}$ register to 1 and increments $\mathit{IP}$
by 2 to move on to the next instruction. The second instruction adds
the value contained at address $c$ to the $\mathit{ACC}$ register, and
increments the $\mathit{IP}$ by 2. At that point, the $\mathit{ACC}$
register holds $1 + v'$. Finally, the last instruction stores the
value of the the $\mathit{ACC}$ register at address $c$. As we
expected, the counter variable thus has value $1+v'$. QED.

\begin{figure}[htbp]
  \begin{center}
    \includestandalone[width=.9\textwidth]{images/assignment.tikz}
  \end{center}
  \caption{Correctness of assignment: Unfolding the effect of three
    instructions on machine state.}
  \label{fig:assignment}
\end{figure}

\begin{takeaway}
  Reasoning about correctness at the RAM instruction level is possible
  but tedious. When possible, we will reason at the pseudo-code level.
\end{takeaway}

\subsection{Conditionals}
Moving on to the next pseudocode construct: The
conditional. Figure~\ref{alg:minimum} shows an algorithm to select the
smallest of two numbers. Figure~\ref{fig:minimum} shows the same
algorithm as a flow chart. How can we show that whatever two numbers
we give, this algorithm will return the minimum?

\begin{figure}[htbp]
  \marginnote{
    \raggedright  
    \scalebox{0.9}{
      \begin{algorithm}[H]
        \KwIn{$(x,\,y) \in \mathbb{Z}^2$}
        \KwOut{$m = \min (x, y)$}
        $m \gets 0$\;
        \eIf{$x < y$}{
          $m \gets x$\;
        }{
          $m \gets y$\;
        }
        \Return{$m$}
      \end{algorithm}}
    \captionof{figure}{Pseudocode of the minimum algorithm}
    \label{alg:minimum}
  }
  \begin{center}
    \includestandalone[width=\textwidth]{images/conditional.tikz}
  \end{center}
  \caption{Reasoning about Conditionals: Merging knowledge gained in all branches}
  \label{fig:minimum}n
\end{figure}

From now on, we will reason---informally---on pseudocode (or code),
but everything could be taken on RAM assembly, should we need a formal
proof, as we did for the assignment (cf. Section~\ref{sec:assignment}).

To prove that our algorithm is correct, we first have to expand the
definition of what is the minimum of a set. One possible definition is
that the minimum must smaller or equals to all elements, which
translates as follows:

\begin{equation}
 \forall \, (x, y) \in \mathbb{Z}^2, \; m = f(x,y) \implies m \leq x \, \land \, m \leq y
\end{equation}

We need to show that this holds
whatever is the path taken through the conditional. We can use a
\emph{prove by cases} here, following the two cases of the
conditionals as follows.

\begin{itemize}
\item if $x<y$, the machine executes the \emph{then}-clause, where we
  set $m$ to $x$. From $m \gets x$ we can conclude that $m = x$, and,
  since in that branch we know that $x<y$, we can conclude that $m<y$.
\item if $x \geq y$, the machine execute sthe \emph{else}-clause,
  where we set $m$ with $y$. The semantics of this assigment
  (cf. Section~\ref{sec:assignment}) allows us to conclude that
  $m = y$, and, since in this branch we know that $x \geq y$, we know
  that $m < x$.
\end{itemize}


\subsection{Iteration}
Consider now a simple loop (i.e., an iteration) that computes the
product of two given numbers. Our algorithm (cf. Figure~\ref{alg:product} and Figure~\ref{fig:product}) implements the
following definition of the product:
\begin{equation}
  x \times y = \overbrace{x+x+\ldots+x}^{y\;\mathrm{times}}
\end{equation}

The loop is the most difficult construct because it raises the
question of \emph{termination}: Is this an ``infinite loop''? For the
assignment and the conditional, the termination directly follows from
the machine following the sequence of instructions. We will first look
at the partial correctness and then at the termination.

\begin{figure}[htbp]
  \marginnote{
    \raggedright  
    \scalebox{0.9}{
      \begin{algorithm}[H]
        \KwIn{$(x,\,y) \in \mathbb{N}^2$}
        \KwOut{$p = x \times y$}
        $p \gets 0$\;
        $c \gets 0$\;
        \While{$c \neq y$}{
          $p \gets p + x$\;
          $c \gets c + 1$\;
        }
        \Return{$p$}
      \end{algorithm}}
    \captionof{figure}{Pseudocode of the product algorithm}
    \label{alg:product}
  }
  \begin{center}
    \includestandalone[width=\textwidth]{images/iteration.tikz}
  \end{center}
  \caption{Reasoning about loops: Finding the \emph{loop invariant}}
  \label{fig:product}
\end{figure}

\paragraph{Partial Correctness} The definition of our algorithm output
tells what we need to prove: $p = x \times y$. We assume that both $x$
and $y$ are positive integers. To reason about the correctness of
loops, we need to find the loop \emph{invariant}\sidenote{Finding such
  invariant is difficult, but, in my experience, it is the key to a
  deeper understanding.}, a property such
that:
\begin{itemize}
\item We can derive our ``aim'' from it. In our case, we must be able
  to derive that $p = x \times y$.
\item It holds \emph{right after} the loop.
\item It holds \emph{right before} the loop
\item It hold \emph{before and after} the loop body
\end{itemize}

Put simply, the loop invariant is always true. In our case the loop invariant is that
$p = c \times x$. To prove the correctness of a loop, we must
therefore prove that the invariant holds, always. This is done by
\emph{induction}\sidenote{See the course appendix about mathematics.}:
First we show it holds before the loop ; then, we show that if it
holds before the loop body, it will hold after. We can do that as
follows:

\begin{itemize}
\item Before the loop body, we know that both $p$ and $c$ are equal to
  zero. So by definition, we get $0 = 0 \times x$, which holds.
\item If we assume that $c'$ and $p'$ are the values before the loop
  body executes, we assume that the invariant holds, that is
  $p' = c' \times x$. After the loop body, we obtain $c = c'+1$ and
  $p=p'+x$. By direct substitution, we get $p = (c'+1) \times x$.
\end{itemize}

It holds. Now, once the machine exits the loop, we know that $c = y$
(i.e., the negation of the loop test) and that $p = c \times x$ (our
invariant). By substitution, we establish that $p = x \times y$. QED.

\paragraph{Termination} Now we know that if we exit the loop we get
the correct result, but are we sure we will ever exit the loop?
Proving termination is difficult and there are algorithms for which we
do not yet know whether they terminate of not\sidenote{See for example the \href{https://en.wikipedia.org/wiki/Collatz_conjecture}{Collatz conjecture}}.

One way to approach loop termination is to identify a \emph{loop
  variant}, which, just like the invariant, is a value $v$ that
behaves as follows:
\begin{itemize}
\item $v$ decreases (strictly) at each time we go through the loop
\item $v \geq 0$ steam from the condition of the loop and the invariant
\end{itemize}

The idea is to show that this variant decreases as long as we remain
in the loop, and that the program exit the loop once it becomes
negative, that is, the program terminates.

Returning to our product algorithm (see Figure~\ref{alg:product}) we
can define $v=y-c$. Initially, since $c$ is set to zero, we got
$v=y$. In each iteration, $v$ decreases by one, as we increment
$c$. We know from the pre-condition that $y \in mathbb{N}$ so $v$ is
necessarily positive in the loop, and will be zero only when the loop
condition breaks. This program terminate.

\begin{takeaway}
  When reasoning about correctness, loops are the main obstacle.
  \begin{itemize}
  \item We tackle \emph{partial correctness} by identifying a
    \emph{loop invariant}, which is true, before, after and during the
    loop.
  \item We tackle \emph{termination} by identifying a \emph{loop
      variant}, which is a quantity that decreases with each iteration
    and can only be negative after the loop.
  \end{itemize}
\end{takeaway}

We see that reasoning formally about correctness is possible but non
trivial. This has been formalized by Floyd and Hoare in what is known
as \emph{axiomatic semantics}\sidenote{This goes beyond the scope of
  this course, but refer to \cite[Chap. 6]{winskel1993} for an
  accessible introduction if you are curious}. We will see how the
same concepts can be use for testing our programs more pragmatically.

\section{Testing}
Formal proofs are difficult, requires expertise, and, in turn, are
largely overpriced for most real-life programs. 

So what do we do in practice? We test. That is, we run our program
with selected inputs for which we know what output to expect. We get
anything else, we have found a problem.

\subsection{The Principles}
\marginnote{%
  \begin{tabular}{rr@{\hskip 2em}r}
    \toprule
    $x$ & $y$ & $x \times y$ \\
    \midrule
    0   & 0   & 0            \\
    5   & 1   & 1            \\
    42  & 10  & 420          \\
    27  & 13  & 351          \\
    \bottomrule
  \end{tabular}
  \captionof{table}{Simple test suite for our product algorithm (see Figure~\ref{fig:product}).}
  \label{tab:test-product}
} The core idea is to prepare a set of correct input/output pairs
(called \emph{test cases}), and to test our program against these. If
our program yields any other results, we have found a
``bug''. Table~\ref{tab:test-product} details four test cases for the
product algorithm. Finding good test cases is the Art of testing.

\paragraph{Running the tests} How do we run an algorithm? It depends
on what we have. If we only have the algorithm, say some pseudocode,
we go pen-and-paper and derive the result from the semantic of our
computation model. Alternatively, if we have an actual program and a
machine, we can simply run it and see what comes out.

\paragraph{Test Cases Selection}
How many \emph{test cases} do we need?  Obviously, there is an
infinity of possible inputs $(x,y) \in \mathbb{N}^2$. The more test
cases our program passes, the more confident we get but we never be
able to test them all. This is the main problem with testing: It
cannot show the absence of errors, only their presence. When all our
tests pass, all we know if that our program worked for theses cases,
but we know nothing about other cases.

Ideally, we want to test all the relevant scenarios with as few test
cases as possible. There are many \emph{coverage criteria} that we can
use to identify relevant scenario. Here are a few common ones:
\begin{itemize}
\item \emph{Covering all statements} implies a set of test cases that exercises
  all the statement of our program. In our product example a single
  test case would be needed, for example $(4, 3)$.
\item \emph{Covering all edges} implies a set of test cases that
  exercises every ``edge'' in associated flow chart (see
  Figure~\ref{fig:product}). Testing our product algorithm with
  $(0,0)$ would not provide edge-coverage.
\item \emph{Condition coverage} implies a set of test cases that each
  condition (or sub-condition) has been evaluated to both true and
  false. In our example, testing with $(4,3)$ would be sufficient
  because the condition $c \neq y$ would initially be false but
  eventually be true.
\end{itemize}

\paragraph{Termination} What happen if our program do not terminate
for some of our test-case? Well, we will never know. If we decide to
interrupt the machine, maybe we have been too impatient and a few more
seconds might have allowed our program to conclude? In practice, we
have to decide on a maximum duration beyond which we consider that the
program will never terminate.

\begin{takeaway}
  Testing is very useful in practice, but it comes with important
  theoretical implications:
  \begin{itemize}
  \item It cannot show the absence of ``bugs'', only their
    presence.
  \item It cannot show non-termination.
  \end{itemize}
\end{takeaway}

\subsection{Diagnostic Using Assertions}
What should we do when a test case fails. We have found a ``bug'' and
we need to fix it. To do this we need to understand what has happened:
Reasoning about our program/algorithm. Fortunately, we have seen how
to do just that when looked at proofs, and the core ideas are very
useful to diagnose problems.

We instrument our programs and add assertion to verify that our
expectation are met. There is no necessity here, but the general
convention is to check the pre-condition and invariants so as to
``fail fast''. If the execution starts on a wrong premises, if often
fails in strange and unexpected manner that are difficult to
debug. Figure~\ref{fig:assertion} shows our Java program instrumented
with additional assertion. Not that Java has built-in exceptions for
illegal arguments (and for illegal states). We also use the ``assert''
keyword whose purpose is precisely to check invariants\sidenote{In
  general we disable all assertions (but the preconditions) before to
  release software. In Java for example, we can use the \texttt{-ea}
  to enable assertions}.

\begin{figure}[htbp]
\begin{minted}{java}
  static int product(int x, int y) {
    if (x < 0)
       throw new IllegalArgumentException("x must be positive");
    if (y < 0)
       throw new IllegalArgumentException("y must be positive");
    int product = 0;
    int counter = 0;
    while (counter != y) {
      assert product == counter * x: "Broken loop invariant";
      product = product + x;
      counter = counter + 1;
    }
    return product;
  }
  \end{minted}
  \caption{A Java implementation of the product algorithm instrumented
    with assertion to help debugging}
  \label{fig:assertion}
\end{figure}

It may look silly to obscure our program with all these
assertions. In practice however the code will be changed soon or later
and these assertions act as ``executable'' documentation of our
intention for the person in charge.x

\subsection{Automated Testing}
In practice we do not test manually. Not only does testing take time,
but we have to test every time we change our programs. To be
productive, we need to be able to test quickly and often so that we
know if we have broken anything\sidenote{This is the core idea behind
  test-driven development (TDD)}.

To do that, we write a separate piece of software that exercises our
program. We rely on frameworks that help us write and runs our tests,
such as \href{https://junit.org/junit5/}{JUnit} for Java,
\href{https://mochajs.org}{Mocha} or \href{https://jestjs.io}{JEST} in
JavaScript,
\href{https://docs.python.org/3/library/unittest.html}{unittest} in
Python, etc. Such \emph{automated tests} are now the {\it de facto}
approach in Industry. Figure~\ref{fig:junit} illustrates a possible
Java implementation of our product algorithm and a simple test
case. When turned into a program, a test case includes three steps:
Arrange, act, assert.
\begin{enumerate}
\item Arrange. First we prepare the input (and possible the state of
  program).
\item Act. We call our program with the selected inputs and collect
  the results.
\item Assert. We verify whether the post-condition of our program holds.
\end{enumerate}

\begin{figure}[htbp]
\begin{minted}{java}
  class MyProductTests {

    @Test
    void testProduct1() {
      assertEquals(20, product(4, 5));
    }

    @Test
    void testProduct2() {
      assertEquals(0, product(0, 0));
    }

  }
  \end{minted}
  \caption{A simple test suite to verify our product program (using JUnit).}
  \label{fig:junit}
\end{figure}

\begin{takeaway}
  Proving, testing and debugging all require a detailed understanding
  of the algorithm. The concepts we use to build proof directly
  support debugging programs:
  \begin{itemize}
  \item Pre-conditions are checked explicitly at the beginning of
    procedures.
  \item Invariants are checked within the procedures using assertion
  \item Post conditions are checked in the automated tests.
  \end{itemize}
\end{takeaway}


\section*{Conclusion}
That is it for algorithms correctness. This was just a peak at the problem
of \emph{Software Verification}---a field in itself. We now know
precisely how to assess the behavior of our algorithms and
programs. Keep in mind that while these techniques may seem tedious,
nothing replace them to learn and understand a new algorithm. We will
then look at comparing algorithms that solve the same problems to
which one perform better.

\bibliographystyle{acm}
\bibliography{references}

\end{document}